---
layout: single
title: "FlowFile 조작을 위한 프로세서 비교"
date: 2025-08-19
categories:
  - Nifi
tags:
  - Nifi
  - FlowFile
  - DataProcessing
  - ETL
toc: true
toc_sticky: true
---

NiFi 데이터 파이프라인에서 FlowFile 콘텐츠를 변환하고 보강하는 작업은 핵심적인 단계입니다. 이 과정에서 어떤 프로세서를 선택하느냐에 따라 파이프라인의 성능과 유지보수성이 크게 달라질 수 있습니다.

이번 포스트에서는 **ReplaceText**, **ReplaceTextwithMapping**, **UpdateRecord**, **JoltTransformJSON** 등 주요 FlowFile 편집 프로세서들의 특징과 사용법을 자세히 살펴보겠습니다.

---

## 1. ReplaceText - 간단한 텍스트 치환

### 특징
- FlowFile에서 원하는 값을 직접 입력하여 치환하는 가장 기본적인 프로세서
- 정규식(Regex) 지원으로 복잡한 패턴 매칭 가능
- 간단한 텍스트 수정에 적합

### 주요 설정
- **Search Value**: 바꾸고자 하는 값 또는 정규식
- **Replacement Value**: 바꿔 넣을 값

### 사용 예시
```text
로그 파일의 IP 주소 마스킹
프로세서 설정
- Search Value: \b(?:[0-9]{1,3}\.){3}[0-9]{1,3}\b
- Replacement Value: ***.***.***.***

입력 데이터 (로그 파일)
[INFO] User 192.168.1.100 accessed /api/users
[ERROR] Connection failed from 10.0.0.50
[INFO] Database query from 172.16.0.25

변환 결과
[INFO] User ***.***.***.*** accessed /api/users
[ERROR] Connection failed from ***.***.***.***
[INFO] Database query from ***.***.***.***
```

---

## 2. ReplaceTextwithMapping - 매핑 기반 치환

### 특징
- 정규식에 검색된 값을 키로 구분하여 여러 변환값을 매핑
- 대량의 치환 작업에 효율적
- 외부 매핑 파일을 통한 유지보수성 향상

### 주요 설정
- **RegularExpression**: 키 값을 잡아낼 정규식
- **Mapping File**: 프로세서 변수로 매핑 파일의 절대경로 지정

### ⚠️ 주의사항
- `|` 연산자로 여러 정규식을 입력할 경우 처리능력이 매우 떨어짐
- 매핑 파일은 운영체제 내부(WSL 등)에서의 절대경로 사용


### 사용 예시

```text
상품의 카테고리 코드를 한글로 변경
프로세서 설정
- RegularExpression: CAT\d{3}
- Mapping File: /opt/nifi/mappings/category_mapping.txt

매핑 파일 내용
CAT001\t전자제품
CAT002\t의류
CAT003\t식품
CAT004\t도서
CAT005\t스포츠용품
매핑 파일은 `키값\t치환값` 형태로 작성하며, `\t`은 탭 키로 입력합니다.


입력 데이터 (주문 내역)
주문번호: ORD001, 상품: CAT001, 수량: 2
주문번호: ORD002, 상품: CAT003, 수량: 1
주문번호: ORD003, 상품: CAT005, 수량: 3

변환 결과
주문번호: ORD001, 상품: 전자제품, 수량: 2
주문번호: ORD002, 상품: 식품, 수량: 1
주문번호: ORD003, 상품: 스포츠용품, 수량: 3
```

---

## 3. UpdateRecord - 레코드 기반 데이터 수정

### 특징
- JSON 데이터의 특정 필드만 선택적으로 수정
- RecordPath 표현식을 통한 정교한 데이터 조작
- 대용량 데이터 처리에 최적화

### Record Reader 선택
JSON 데이터를 읽는 recored reader 항목에는 두 가지 옵션이 있습니다

1. **JsonTreeReader** (권장)
   - 전체 JSON 구조 유지
   - 안전하고 예측 가능한 동작
   - 데이터의 일부만 변경할 경우

2. **JsonPathReader**
   - 지정된 path 이외의 데이터를 모두 제거
   - 데이터 손실 위험
   - 특정 데이터만 필요한 경우

### 주요 설정
- **Record Reader**: JsonTreeReader 또는 JsonPathReader
- **Record Set Writer**: JsonRecordSetWriter
- **Replacement Value Strategy**: Record Path Value로 설정


### 프로퍼티 설정 

**프로퍼티 명:** 조작할 데이터의 JSON path 형태
```bash
/author
/category/snacks
```

**프로퍼티 값:** RecordPath 표현식을 사용한 데이터 수정 로직
```bash
replace(replace(toLowerCase(/author), ',', ''), '-', ' ')
trim(/publication_country)
```


### RecordPath 표현식 예시
```bash
replace(replaceRegex(/data, '^.*$','k'), 'k', 't')
```

### ⚠️ 주의사항
- JsonRecordSetWriter 사용 시 반환값은 항상 Array에 감싸진 형태
- 데이터를 개별 데이터로 분할하기 전에 사용하는 것을 권장

### 사용 예시
```text
프로세서 설정
- Record Reader: JsonTreeReader
- Record Set Writer: JsonRecordSetWriter
- 프로퍼티: 
  /customerName = trim(/customerName)
  /phoneNumber = replaceRegex(/phoneNumber, '[^0-9]', '')
  /email = toLowerCase(/email)

입력 JSON (고객 데이터)
[
  {
    "customerId": "C001",
    "customerName": "  김철수  ",
    "phoneNumber": "010-123-4567",
    "email": "KIM@EXAMPLE.COM",
    "status": "active"
  },
  {
    "customerId": "C002", 
    "customerName": "이영희",
    "phoneNumber": "010.987.6543",
    "email": "LEE@EXAMPLE.COM",
    "status": "inactive"
  }
]

변환 결과
[
  {
    "customerId": "C001",
    "customerName": "김철수",
    "phoneNumber": "0101234567",
    "email": "kim@example.com",
    "status": "active"
  },
  {
    "customerId": "C002",
    "customerName": "이영희", 
    "phoneNumber": "0109876543",
    "email": "lee@example.com",
    "status": "inactive"
  }
]
```

### 장점
- 특정 Path의 데이터만 조회하므로 FlowFileContent가 방대할 때 유용
- ReplaceText는 전체 데이터에서 정규식 검색을 하지만, UpdateRecord는 선택적 처리가 가능
- 스키마(Schema) 기반으로 동작하기 때문에, FlowFile의 전체 내용을 메모리에 로드하지 않고 스트리밍 방식으로 레코드를 하나씩 처리함

---

## 4. JoltTransformJSON - 고급 JSON 변환

### 특징
- JOLT(JSON to JSON Transformation Language) 기반
- 복잡한 JSON 구조 변환에 특화
- 체인 형태로 여러 변환 작업을 순차적으로 처리

### Jolt Transformation DSL
- **Chain** 모드로 설정하여 여러 요청을 한번에 처리
- 모든 operation 객체들은 배열 안에 존재해야 함

### 주요 Operation 유형

#### 1. modify-overwrite-beta
필드의 값을 직접 조작할 때 사용
```json
{
  "operation": "modify-overwrite-beta",
  "spec": {
    "author": "=trim(@(1,author))",
    "description": "=split(',', @(1,description))",
    "content": "=replace(@(1,content), 'old_word', 'new_word')"
  }
}

// 입력 데이터
{
  "author": "  John Doe  ",
  "description": "nifi,jolt,json",
  "content": "This is the old_word."
}

// 출력 데이터
{
  "author" : "John Doe",
  "description" : [ "nifi", "jolt", "json" ],
  "content" : "This is the new_word."
}
```

#### 2. shift
구성 재배치, 키값 변경 등에 사용
```json
{
  "operation": "shift",
  "spec": {
    "customer": {
      "name": "client.fullName",
      "birthDate": "client.dateOfBirth",
      "address": "client.address.street",
      "country": "client.address.country"
    }
  }
}

// 입력 데이터
{
  "orderId": "abc-123",
  "customer": {
    "name": "홍길동",
    "birthDate": "1995-01-10",
    "address": "서울시 강남구 테헤란로",
    "country": "대한민국"
  }
}

// 출력 데이터
{
  "client" : {
    "fullName" : "홍길동",
    "dateOfBirth" : "1995-01-10",
    "address" : {
      "street" : "서울시 강남구 테헤란로",
      "country" : "대한민국"
    }
  }
}
```
**필드 명칭**
- **LHS (Left Hand Side)**: 변환할 필드 경로 (키 위치)
- **RHS (Right Hand Side)**: 변환 결과를 저장할 필드 경로 (값 위치)

**특수 연산자:**
- `&`: 기존 필드명 재사용
- `"user-&"`: 접두어 추가
- `"&-info"`: 접미어 추가



#### 3. default
존재하지 않는 필드에 대한 기본값 추가
```json
{
  "operation": "default",
  "spec": {
    "status": "active",
    "is_checked": false
  }
}

// 입력 데이터 (status 필드가 없음)
{
  "id": "item-100"
}

// 출력 데이터
{
  "id": "item-100",
  "status": "active",
  "is_checked": false
}
```

#### 4. remove
지정된 필드를 JSON에서 제거
```json
{
  "operation": "remove",
  "spec": {
    "temp_id": "",
    "user": {
      "log": ""
    }
  }
}

// 입력 데이터
{
  "id": 123,
  "temp_id": "temp_xyz",
  "user": {
    "name": "Alice",
    "log": "user logged in"
  }
}

// 출력 데이터
{
  "id": 123,
  "user": {
    "name": "Alice"
  }
}
```

#### 5. sort
입력된 JSON 객체의 키를 알파벳 순으로 정렬
```json
{
  "operation": "sort"
}
```

#### 6. cardinality
배열과 단일 값 간의 변환
- ONE : 배열을 단일 값으로 변경 (첫 번째 값만 남김)
- MANY : 단일 값을 배열로 만듦 (크기 1의 배열)

```json
{
  "operation": "cardinality",
  "spec": {
    "tags": "ONE"    
  }
}
```

### Jolt 스펙 작성 예시

```json
[
  {
    "operation": "shift",
    "spec": {
      "customer": {
        "name": "client.fullName",
        "birthDate": "client.dateOfBirth",
        "address": "client.address.street",
        "country": "client.address.country"
      }
    }
  },
  {
    "operation": "modify-overwrite-beta",
    "spec": {
      "client.fullName": "=trim",
      "client.address.street": "=toLowerCase"
    }
  },
  ......
]
```

---

## 프로세서 선택 가이드

### 언제 어떤 프로세서를 사용할까?

| 상황 | 권장 프로세서 | 이유 |
|------|---------------|------|
| 간단한 텍스트 치환 | ReplaceText | 설정 간단, 직관적 |
| 대량의 치환 작업 | ReplaceTextwithMapping | 외부 파일로 관리 용이 |
| JSON 특정 필드 수정 | UpdateRecord | 성능 우수, 선택적 처리 |
| 복잡한 JSON 구조 변환 | JoltTransformJSON | 강력한 변환 기능 |

### 성능 고려사항
- **ReplaceText**: 전체 텍스트 검색으로 대용량 데이터 시 성능 저하
- **UpdateRecord**: 선택적 처리로 대용량 데이터에 최적화
- **JoltTransformJSON**: 복잡한 변환 시 체인 길이에 따라 성능 영향

---

## 결론

Apache NiFi의 FlowFile 편집 프로세서는 각각의 장단점이 있습니다. 

- **간단한 작업**에는 ReplaceText
- **체계적인 치환**에는 ReplaceTextwithMapping  
- **JSON 필드 수정**에는 UpdateRecord
- **복잡한 JSON 변환**에는 JoltTransformJSON

을 사용하는 것이 적절합니다.

프로젝트의 요구사항과 데이터 특성을 고려하여 적절한 프로세서를 선택하고, 필요에 따라 여러 프로세서를 조합하여 사용하는 것이 효과적입니다.

---

## 참고 자료

- [Apache NiFi RecordPath Guide](https://nifi.apache.org/docs/nifi-docs/html/record-path-guide.html)
- [JOLT GitHub Repository](https://github.com/bazaarvoice/jolt)
- [Apache NiFi User Guide](https://nifi.apache.org/docs.html)
